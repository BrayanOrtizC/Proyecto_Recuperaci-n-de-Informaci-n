{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11958864,"sourceType":"datasetVersion","datasetId":7519331}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Proyecto de Recuperaci√≥n de Informaci√≥n: Dataset Cranfield\n### Motor de B√∫squeda Vectorial y Probabil√≠stico para Ingenier√≠a Aeron√°utica\n\n**Autor:** Fabian Simba√±a, Brayan Ortiz.\n\n**Dataset:** Cranfield Collection (1400 abstracts sobre aerodin√°mica).\n\n### Objetivo.\nDise√±ar e implementar un sistema de recuperaci¬¥on de informaci¬¥on que indexe un conjunto de documentos en\ntexto plano y permita ejecutar consultas de texto libre utilizando el modelo vectorial con vectores binarios\ny ponderaci√≥n TF-IDF, y el modelo probabil¬¥ƒ±stico BM25. El sistema debe permitir evaluar la calidad de los\nresultados utilizando m¬¥etricas est¬¥andar como precision y recall.\n### Arquitectura.\n1.  **Preprocesamiento de Dominio:**\n    * Normalizaci√≥n.\n    * Limpieza de ruido \"acad√©mico\" espec√≠fico de ingenier√≠a (ej: *calculated, measured*).\n    * Preservaci√≥n de terminolog√≠a t√©cnica con guiones (ej: *quasi-linear*).\n    * Stemming (Porter) para normalizaci√≥n morfol√≥gica.\n3.  **Modelos Implementados (From Scratch):**\n    * **Jaccard:** Coeficiente de similitud de conjuntos.\n    * **TF-IDF:** Modelo vectorial con suavizado logar√≠tmico ($1 + \\log(tf)$).\n    * **BM25:** Modelo probabil√≠stico calibrado($k_1=1.8, b=0.9$).\n4.  **Evaluaci√≥n:**\n    * M√©tricas estandarizadas: **MAP**, **Precision@10**, **Recall@10**.","metadata":{"execution":{"iopub.status.busy":"2025-12-10T03:21:45.996988Z","iopub.execute_input":"2025-12-10T03:21:45.997313Z","iopub.status.idle":"2025-12-10T03:21:46.005906Z","shell.execute_reply.started":"2025-12-10T03:21:45.997289Z","shell.execute_reply":"2025-12-10T03:21:46.004580Z"}}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nimport math\nimport nltk\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom numpy.linalg import norm\nimport os\n\n# =============================================================================\n# 1. PREPROCESAMIENTO DE TEXTO (DOMINIO: INGENIER√çA)\n# =============================================================================\n\n# Descarga de recursos b√°sicos\ntry:\n    nltk.data.find('corpora/stopwords')\nexcept LookupError:\n    nltk.download('stopwords', quiet=True)\n\nstemmer = PorterStemmer()\n\n# --- A. DEFINICI√ìN DE STOPWORDS ---\n# Lista base de ingl√©s\nlista_stopwords_raw = set(stopwords.words('english'))\n\n# RUIDO ESPEC√çFICO DE CRANFIELD:\n# Palabras metodol√≥gicas que aparecen en casi todos los papers y no discriminan.\ncranfield_noise = {\n    # T√©rminos generales\n    'abstract', 'paper', 'report', 'note', 'present', 'discuss', \n    'introduction', 'conclus', 'conclusion', 'result', 'obtain', \n    'shown', 'show', 'give', 'given', 'studi', 'study', 'investig', \n    'investigation', 'research', 'work', 'development', 'consider',\n    \n    # Verbos/Acciones (Ruido alto en ingenier√≠a)\n    'method', 'approach', 'technique', 'use', 'using', 'base', 'based',\n    'determin', 'determine', 'calcul', 'calculate', 'comput', \n    'measur', 'measure', 'measurement', 'estim', 'estimate',\n    'experi', 'experiment', 'experimental', 'test', 'analy', 'analysis',\n    'appl', 'appli', 'application', 'compar', 'comparison',\n    \n    # T√©rminos abstractos\n    'effect', 'affect', 'influence', 'theori', 'theory', 'theoretical',\n    'problem', 'solut', 'solution', 'case', 'approxim', 'approximate', \n    'approximation', 'condit', 'condition', 'gener', 'general',\n    'valu', 'value', 'number', 'agree', 'agreement', 'data', 'time', \n    'year', 'refer', 'reference', 'equat', 'equation', 'deriv', 'derivation',\n    'variou', 'various', 'possibl', 'possible', 'type'\n}\n\nlista_stopwords_raw.update(cranfield_noise)\nstop_words_stemmed = set([stemmer.stem(w) for w in lista_stopwords_raw])\n\ndef procesar_texto_seguro(texto):\n    \"\"\"\n    Pipeline de limpieza optimizado para textos t√©cnicos:\n    1. Regex: Mantiene alfanum√©ricos y GUIONES (-) (vital para 'steady-flow').\n    2. Stemming: Reduce variaciones morfol√≥gicas.\n    3. Filtrado: Elimina stopwords generales y de dominio.\n    \"\"\"\n    if not isinstance(texto, str): return []\n    \n    # 1. Limpieza (Conservamos guiones internos)\n    text = re.sub(pattern=r\"<.*?>\", repl=' ', string=texto.lower())\n    text = re.sub(r\"[^a-z0-9\\s-]\", ' ', text)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    \n    tokens = text.split()\n    tokens_procesados = []\n    \n    # 2. Normalizaci√≥n y Filtrado\n    for t in tokens:\n        # Filtramos guiones sueltos o palabras muy cortas\n        if len(t) > 2 and t != '-': \n            raiz = stemmer.stem(t)\n            if raiz not in stop_words_stemmed and len(raiz) > 2:\n                tokens_procesados.append(raiz)\n    \n    return tokens_procesados\n\nprint(\"Configuraci√≥n cargada: Preprocesamiento optimizado para Cranfield.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-10T03:54:21.454362Z","iopub.execute_input":"2025-12-10T03:54:21.456318Z","iopub.status.idle":"2025-12-10T03:54:21.494497Z","shell.execute_reply.started":"2025-12-10T03:54:21.456280Z","shell.execute_reply":"2025-12-10T03:54:21.493258Z"}},"outputs":[{"name":"stdout","text":"Configuraci√≥n cargada: Preprocesamiento optimizado para Cranfield.\n","output_type":"stream"}],"execution_count":97},{"cell_type":"code","source":"# =============================================================================\n# 2. MODELOS DE RECUPERACI√ìN\n# =============================================================================\n\n# --- A. JACCARD (Similitud de Conjuntos) ---\ndef busqueda_jaccard(consulta, corpus, top_n=10):\n    query_tokens = set(procesar_texto_seguro(consulta))\n    scores = []\n    for i, doc_tokens in enumerate(corpus):\n        doc_set = set(doc_tokens)\n        if not query_tokens or not doc_set: continue\n        \n        intersection = len(query_tokens & doc_set)\n        union = len(query_tokens | doc_set)\n        coef = intersection / union\n        \n        if coef > 0: scores.append((i, coef))\n    return sorted(scores, key=lambda x: x[1], reverse=True)[:top_n]\n\n# --- B. TF-IDF (Vectorial con Log-Normalizaci√≥n) ---\ndef obtener_vocabulario(corpus):\n    vocab = set()\n    for doc in corpus: vocab.update(doc)\n    return sorted(list(vocab))\n\ndef calcular_idf(corpus, vocab):\n    N = len(corpus)\n    idf = {}\n    df_counts = Counter()\n    for doc in corpus: df_counts.update(set(doc))\n    for word, count in df_counts.items():\n        # IDF Est√°ndar base 10\n        idf[word] = math.log10(N / (count + 1))\n    return idf\n\ndef generar_matriz_tfidf(corpus, vocab, idf_dict):\n    matriz = []\n    for doc in corpus:\n        tf_dict = Counter(doc)\n        vector = []\n        for word in vocab:\n            raw_tf = tf_dict[word]\n            # Suavizado Logar√≠tmico: 1 + log(tf)\n            tf = (1 + math.log(raw_tf)) if raw_tf > 0 else 0\n            vector.append(tf * idf_dict.get(word, 0))\n        matriz.append(vector)\n    return pd.DataFrame(matriz, columns=vocab)\n\ndef busqueda_tfidf(consulta, matriz_tfidf, vocab, idf_dict, top_n=10):\n    tokens = procesar_texto_seguro(consulta)\n    q_counts = Counter(tokens)\n    vec_q = []\n    for word in vocab:\n        raw_tf = q_counts[word]\n        tf = (1 + math.log(raw_tf)) if raw_tf > 0 else 0\n        vec_q.append(tf * idf_dict.get(word, 0))\n    vec_q = np.array(vec_q)\n    \n    norm_q = norm(vec_q)\n    if norm_q == 0: return []\n    \n    scores = []\n    for i, row in matriz_tfidf.iterrows():\n        vec_d = np.array(row)\n        norm_d = norm(vec_d)\n        dot = np.dot(vec_q, vec_d)\n        sim = dot / (norm_q * norm_d) if norm_d > 0 else 0\n        if sim > 0: scores.append((i, sim))\n    return sorted(scores, key=lambda x: x[1], reverse=True)[:top_n]\n\n# --- C. BM25 (Probabil√≠stico) ---\ndef obtener_estadisticas_bm25(corpus):\n    doc_lens = [len(d) for d in corpus]\n    return doc_lens, sum(doc_lens) / len(corpus)\n\ndef calcular_idf_bm25(corpus):\n    N = len(corpus)\n    idf = {}\n    df_counts = Counter()\n    for doc in corpus: df_counts.update(set(doc))\n    for word, count in df_counts.items():\n        # IDF Probabil√≠stico\n        idf[word] = math.log((N - count + 0.5) / (count + 0.5) + 1)\n    return idf\n\ndef busqueda_bm25(consulta, corpus, doc_lens, avgdl, idf_bm25, k1=1.8, b=0.9, top_n=10):\n    q_tokens = procesar_texto_seguro(consulta)\n    scores = []\n    for i, doc in enumerate(corpus):\n        score = 0\n        doc_counts = Counter(doc)\n        for token in q_tokens:\n            if token in doc_counts:\n                tf = doc_counts[token]\n                numerador = tf * (k1 + 1)\n                denominador = tf + k1 * (1 - b + b * (doc_lens[i] / avgdl))\n                score += idf_bm25.get(token, 0) * (numerador / denominador)\n        if score > 0: scores.append((i, score))\n    return sorted(scores, key=lambda x: x[1], reverse=True)[:top_n]\n\nprint(\"‚úÖ Modelos definidos correctamente.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T03:54:21.496805Z","iopub.execute_input":"2025-12-10T03:54:21.497058Z","iopub.status.idle":"2025-12-10T03:54:21.522245Z","shell.execute_reply.started":"2025-12-10T03:54:21.497040Z","shell.execute_reply":"2025-12-10T03:54:21.521231Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Modelos definidos correctamente.\n","output_type":"stream"}],"execution_count":98},{"cell_type":"code","source":"# =============================================================================\n# 3. CARGA DE DATOS CRANFIELD\n# =============================================================================\n\npath_docs_folder = \"/kaggle/input/cranfield-dataset/Cranfield\"\npath_query_file = \"/kaggle/input/cranfield-dataset/TEST/query.txt\"\npath_qrels_folder = \"/kaggle/input/cranfield-dataset/TEST/RES\"\n\n# 1. PARSER DE DOCUMENTOS\ndef cargar_docs_cranfield(ruta_carpeta):\n    data = {}\n    if not os.path.exists(ruta_carpeta): return data\n    archivos = os.listdir(ruta_carpeta)\n    print(f\"Cargando documentos desde {ruta_carpeta}...\")\n    for archivo in archivos:\n        if archivo.endswith(\".txt\"):\n            try:\n                doc_id = int(archivo.replace('.txt', ''))\n                with open(os.path.join(ruta_carpeta, archivo), 'r', encoding='utf-8', errors='ignore') as f:\n                    data[doc_id] = {'T': '', 'W': f.read()}\n            except: continue\n    return data\n\n# 2. PARSER DE CONSULTAS (L√≠nea por l√≠nea)\ndef cargar_queries_cranfield(ruta_archivo):\n    data = {}\n    if not os.path.exists(ruta_archivo): return data\n    print(f\"Cargando consultas desde {ruta_archivo}...\")\n    with open(ruta_archivo, 'r', encoding='utf-8', errors='ignore') as f:\n        lines = f.readlines()\n    for idx, line in enumerate(lines):\n        line = line.strip()\n        if len(line) > 5:\n            data[idx + 1] = {'W': line}\n    return data\n\n# 3. PARSER DE QRELS\ndef cargar_qrels_cranfield(ruta_carpeta):\n    qrels_list = []\n    if not os.path.exists(ruta_carpeta): return pd.DataFrame()\n    print(f\"Cargando Ground Truth (QRELS)...\")\n    archivos = os.listdir(ruta_carpeta)\n    for archivo in archivos:\n        if archivo.endswith(\".txt\"):\n            try:\n                query_id = int(archivo.replace('.txt', ''))\n                with open(os.path.join(ruta_carpeta, archivo), 'r') as f:\n                    content = f.read()\n                numeros = content.replace('\\n', ' ').split()\n                for item in numeros:\n                    if item.isdigit():\n                        qrels_list.append([query_id, int(item), 1])\n            except: continue\n    return pd.DataFrame(qrels_list, columns=['query_id', 'document_id', 'relevance'])\n\nprint(\"INICIANDO SISTEMA...\")\ndocuments = cargar_docs_cranfield(path_docs_folder)\nqueries = cargar_queries_cranfield(path_query_file)\nqrels_df = cargar_qrels_cranfield(path_qrels_folder)\n\nprint(f\"\\nESTAD√çSTICAS DEL DATASET:\")\nprint(f\"   -> Documentos: {len(documents)}\")\nprint(f\"   -> Consultas: {len(queries)}\")\nprint(f\"   -> Qrels: {len(qrels_df)}\")\n\n# --- CONSTRUCCI√ìN DEL CORPUS ---\nif len(documents) > 0:\n    print(\"\\nProcesando corpus (Limpieza + Stemming)...\")\n    corpus_tokens = []\n    map_indices_id = [] \n    \n    for doc_id in sorted(documents.keys()):\n        data = documents[doc_id]\n        texto = f\"{data.get('T', '')} {data.get('W', '')}\"\n        corpus_tokens.append(procesar_texto_seguro(texto))\n        map_indices_id.append(doc_id)\n\n    print(\"Generando √≠ndices invertidos...\")\n    vocab = obtener_vocabulario(corpus_tokens)\n    idf_tfidf = calcular_idf(corpus_tokens, vocab)\n    matriz_tfidf = generar_matriz_tfidf(corpus_tokens, vocab, idf_tfidf)\n    doc_lengths, avgdl = obtener_estadisticas_bm25(corpus_tokens)\n    idf_bm25 = calcular_idf_bm25(corpus_tokens)\n    \n    print(\"SISTEMA LISTO.\")\nelse:\n    print(\"ERROR: No se cargaron documentos.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T03:54:21.523390Z","iopub.execute_input":"2025-12-10T03:54:21.523743Z","iopub.status.idle":"2025-12-10T03:54:30.972308Z","shell.execute_reply.started":"2025-12-10T03:54:21.523714Z","shell.execute_reply":"2025-12-10T03:54:30.970696Z"}},"outputs":[{"name":"stdout","text":"INICIANDO SISTEMA...\nCargando documentos desde /kaggle/input/cranfield-dataset/Cranfield...\nCargando consultas desde /kaggle/input/cranfield-dataset/TEST/query.txt...\nCargando Ground Truth (QRELS)...\n\nESTAD√çSTICAS DEL DATASET:\n   -> Documentos: 1400\n   -> Consultas: 225\n   -> Qrels: 5285\n\nProcesando corpus (Limpieza + Stemming)...\nGenerando √≠ndices invertidos...\nSISTEMA LISTO.\n","output_type":"stream"}],"execution_count":99},{"cell_type":"code","source":"def evaluar_sistema_completo(nombre_modelo):\n    print(f\"\\n--- Evaluando Modelo: {nombre_modelo} ---\")\n    aps, precisions, recalls = [], [], []\n    \n    for q_id, q_data in queries.items():\n        if q_id not in qrels_df['query_id'].values: continue\n        relevantes = set(qrels_df[qrels_df['query_id'] == q_id]['document_id'].values)\n        \n        # B√öSQUEDA (Top 200-300 para asegurar buen c√°lculo de MAP)\n        if nombre_modelo == 'Jaccard':\n            ranking = busqueda_jaccard(q_data['W'], corpus_tokens, top_n=200)\n        elif nombre_modelo == 'TF-IDF':\n            ranking = busqueda_tfidf(q_data['W'], matriz_tfidf, vocab, idf_tfidf, top_n=200)\n        elif nombre_modelo == 'BM25':\n            ranking = busqueda_bm25(q_data['W'], corpus_tokens, doc_lengths, avgdl, idf_bm25, \n                                    k1=1.8, b=0.9, top_n=200)\n            \n        # M√©tricas (MAP)\n        hits, sum_precisions = 0, 0\n        for i, (idx, _) in enumerate(ranking):\n            if map_indices_id[idx] in relevantes:\n                hits += 1\n                sum_precisions += hits / (i + 1)\n        ap = sum_precisions / len(relevantes) if relevantes else 0\n        aps.append(ap)\n        \n        # M√©tricas (@10)\n        top_10 = ranking[:10]\n        hits_10 = sum(1 for idx, _ in top_10 if map_indices_id[idx] in relevantes)\n        precisions.append(hits_10 / 10.0)\n        recalls.append(hits_10 / len(relevantes) if len(relevantes) > 0 else 0)\n\n    print(f\"Resultados Globales {nombre_modelo}:\")\n    print(f\"-> MAP:          {np.mean(aps):.4f}\")\n    print(f\"-> Precision@10: {np.mean(precisions):.4f}\")\n    print(f\"-> Recall@10:    {np.mean(recalls):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T03:54:30.974136Z","iopub.execute_input":"2025-12-10T03:54:30.974445Z","iopub.status.idle":"2025-12-10T03:54:30.985231Z","shell.execute_reply.started":"2025-12-10T03:54:30.974423Z","shell.execute_reply":"2025-12-10T03:54:30.984048Z"}},"outputs":[],"execution_count":100},{"cell_type":"code","source":"# =============================================================================\n# DEMOSTRACI√ìN T√âCNICA (Requerimientos A y B)\n# =============================================================================\n\ndef mostrar_cumplimiento_req_a():\n    print(\"\\n\" + \"=\"*70)\n    print(\"REQUERIMIENTO A: PROCESAMIENTO DE TEXTO (Limpieza + Stemming)\")\n    print(\"=\"*70)\n    print(\"Objetivo: Mostrar la transformaci√≥n de texto crudo a tokens procesados.\\n\")\n    \n    doc_id_demo = 1\n    if doc_id_demo not in documents: doc_id_demo = list(documents.keys())[0]\n    texto_original = documents[doc_id_demo]['W']\n    \n    print(f\"1. TEXTO ORIGINAL (Raw Input):\")\n    print(f\"'{texto_original[:150]}...'\\n\")\n    \n    # Simulaci√≥n visual de pasos intermedios\n    texto_limpio = re.sub(r\"[^a-z0-9\\s-]\", ' ', texto_original.lower())\n    print(f\"2. LIMPIEZA (Regex + Guiones preservados):\")\n    print(f\"'{texto_limpio[:150]}...'\\n\")\n    \n    # Procesamiento real\n    tokens_finales = procesar_texto_seguro(texto_original)\n    \n    print(f\"3. TOKENIZACI√ìN + STEMMING (Salida del √çndice):\")\n    print(f\"   [Tokens]: {tokens_finales[:15]}...\")\n    print(f\"\\n   Total Tokens: {len(tokens_finales)} (Originales: {len(texto_original.split())})\")\n    print(\"   Nota: Se eliminaron stopwords de ingenier√≠a ('experimental', 'investigation') y se normaliz√≥.\")\n\ndef mostrar_cumplimiento_req_b():\n    print(\"\\n\" + \"=\"*70)\n    print(\"REQUERIMIENTO B: COMPARATIVA DE MODELOS\")\n    print(\"=\"*70)\n    \n    consulta_demo = \"boundary layer flow separation\"\n    print(f\"Consulta de Prueba: '{consulta_demo}'\\n\")\n    \n    # Top 1 de cada modelo\n    res_jaccard = busqueda_jaccard(consulta_demo, corpus_tokens, top_n=1)\n    res_tfidf = busqueda_tfidf(consulta_demo, matriz_tfidf, vocab, idf_tfidf, top_n=1)\n    res_bm25 = busqueda_bm25(consulta_demo, corpus_tokens, doc_lengths, avgdl, idf_bm25, top_n=1)\n    \n    print(f\"{'MODELO':<10} | {'DOC ID':<8} | {'SCORE':<10} | {'CONTENIDO'}\")\n    print(\"-\" * 80)\n    \n    def imprimir(nombre, res):\n        if res:\n            idx, score = res[0]\n            doc_id = map_indices_id[idx]\n            txt = documents[doc_id]['W'][:40].replace('\\n', ' ') + \"...\"\n            print(f\"{nombre:<10} | {doc_id:<8} | {score:.4f}     | {txt}\")\n        else:\n            print(f\"{nombre:<10} | {'---':<8} | {'0.0000':<10} | ---\")\n\n    imprimir(\"Jaccard\", res_jaccard)\n    imprimir(\"TF-IDF\", res_tfidf)\n    imprimir(\"BM25\", res_bm25)\n    print(\"\\nConclusi√≥n: BM25 demuestra mayor discriminaci√≥n gracias a su funci√≥n de saturaci√≥n.\")\n\n# Ejecutar demos\nmostrar_cumplimiento_req_a()\nmostrar_cumplimiento_req_b()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T03:54:30.986312Z","iopub.execute_input":"2025-12-10T03:54:30.986661Z","iopub.status.idle":"2025-12-10T03:54:31.268553Z","shell.execute_reply.started":"2025-12-10T03:54:30.986623Z","shell.execute_reply":"2025-12-10T03:54:31.267514Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nREQUERIMIENTO A: PROCESAMIENTO DE TEXTO (Limpieza + Stemming)\n======================================================================\nObjetivo: Mostrar la transformaci√≥n de texto crudo a tokens procesados.\n\n1. TEXTO ORIGINAL (Raw Input):\n'experimental investigation of the aerodynamics of a wing in a slipstream . an experimental study of a wing in a propeller slipstream was made in order...'\n\n2. LIMPIEZA (Regex + Guiones preservados):\n'experimental investigation of the aerodynamics of a wing in a slipstream   an experimental study of a wing in a propeller slipstream was made in order...'\n\n3. TOKENIZACI√ìN + STEMMING (Salida del √çndice):\n   [Tokens]: ['aerodynam', 'wing', 'slipstream', 'wing', 'propel', 'slipstream', 'made', 'order', 'spanwis', 'distribut', 'lift', 'increas', 'due', 'slipstream', 'differ']...\n\n   Total Tokens: 64 (Originales: 145)\n   Nota: Se eliminaron stopwords de ingenier√≠a ('experimental', 'investigation') y se normaliz√≥.\n\n======================================================================\nREQUERIMIENTO B: COMPARATIVA DE MODELOS\n======================================================================\nConsulta de Prueba: 'boundary layer flow separation'\n\nMODELO     | DOC ID   | SCORE      | CONTENIDO\n--------------------------------------------------------------------------------\nJaccard    | 3        | 0.2308     | the boundary layer in simple shear flow ...\nTF-IDF     | 358      | 0.4248     | on the model of the free shock separatio...\nBM25       | 358      | 11.0899     | on the model of the free shock separatio...\n\nConclusi√≥n: BM25 demuestra mayor discriminaci√≥n gracias a su funci√≥n de saturaci√≥n.\n","output_type":"stream"}],"execution_count":101},{"cell_type":"code","source":"def comparar_modelos_visual(query_id_prueba=1):\n    \"\"\"\n    Ejecuta Jaccard, TF-IDF y BM25 para una misma consulta y muestra\n    cu√°les aciertan (‚úÖ) y cu√°les fallan (‚ùå) seg√∫n las QRELS.\n    \"\"\"\n    # 1. Obtener datos de la consulta\n    if query_id_prueba not in queries:\n        print(\"ID de consulta no encontrado.\")\n        return\n\n    texto_consulta = queries[query_id_prueba]['W']\n    print(f\"üîé CONSULTA ID {query_id_prueba}:\")\n    print(f\"'{texto_consulta[:100]}...'\\n\")\n    \n    # 2. Obtener la 'Hoja de Respuestas' (QRELS)\n    relevantes_reales = set(qrels_df[qrels_df['query_id'] == query_id_prueba]['document_id'].values)\n    print(f\"üìÑ Documentos Relevantes Totales en QRELS: {len(relevantes_reales)}\")\n    print(\"-\" * 60)\n\n    # --- FUNCI√ìN AUXILIAR PARA IMPRIMIR RESULTADOS ---\n    def mostrar_ranking(nombre, resultados):\n        print(f\"\\n>> {nombre} (Top 10):\")\n        hits = 0\n        for i, (idx, score) in enumerate(resultados[:10]): # Solo mostramos Top 5 para no saturar\n            id_real = map_indices_id[idx]\n            titulo = documents[id_real].get('T', 'Sin t√≠tulo').strip()[:50]\n            \n            # EL MOMENTO DE LA VERDAD:\n            if id_real in relevantes_reales:\n                marca = \"‚úÖ ACERTO\"\n                hits += 1\n            else:\n                marca = \"‚ùå FALLO\"\n            \n            print(f\"   {i+1}. [Doc {id_real}] {marca} | Score: {score:.4f} | {titulo}...\")\n        print(f\"   RESUMEN: {hits}/10 relevantes encontrados.\")\n\n    # 3. EJECUTAR LOS 3 MODELOS\n    \n    # A. JACCARD\n    res_jaccard = busqueda_jaccard(texto_consulta, corpus_tokens, top_n=10)\n    mostrar_ranking(\"MODELO 1: JACCARD (Binario)\", res_jaccard)\n    \n    # B. TF-IDF\n    res_tfidf = busqueda_tfidf(texto_consulta, matriz_tfidf, vocab, idf_tfidf, top_n=10)\n    mostrar_ranking(\"MODELO 2: TF-IDF (Vectorial)\", res_tfidf)\n    \n    # C. BM25\n    res_bm25 = busqueda_bm25(texto_consulta, corpus_tokens, doc_lengths, avgdl, idf_bm25, top_n=10)\n    mostrar_ranking(\"MODELO 3: BM25 (Probabil√≠stico)\", res_bm25)\n    \n    print(\"\\n\" + \"=\"*60)\n\n# --- PRUEBA CON UNA CONSULTA DIF√çCIL ---\n# La consulta 1 es buena, pero prueba tambi√©n la 3 o la 10\ncomparar_modelos_visual(20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T04:03:54.738453Z","iopub.execute_input":"2025-12-10T04:03:54.738838Z","iopub.status.idle":"2025-12-10T04:03:55.012083Z","shell.execute_reply.started":"2025-12-10T04:03:54.738813Z","shell.execute_reply":"2025-12-10T04:03:55.010862Z"}},"outputs":[{"name":"stdout","text":"üîé CONSULTA ID 20:\n'20\thas anyone formally determined the influence of joule heating,  produced by the induced current, ...'\n\nüìÑ Documentos Relevantes Totales en QRELS: 12\n------------------------------------------------------------\n\n>> MODELO 1: JACCARD (Binario) (Top 10):\n   1. [Doc 407] ‚úÖ ACERTO | Score: 0.1429 | ...\n   2. [Doc 500] ‚úÖ ACERTO | Score: 0.1250 | ...\n   3. [Doc 268] ‚úÖ ACERTO | Score: 0.1020 | ...\n   4. [Doc 963] ‚ùå FALLO | Score: 0.0968 | ...\n   5. [Doc 269] ‚úÖ ACERTO | Score: 0.0930 | ...\n   6. [Doc 450] ‚ùå FALLO | Score: 0.0882 | ...\n   7. [Doc 1158] ‚ùå FALLO | Score: 0.0882 | ...\n   8. [Doc 88] ‚úÖ ACERTO | Score: 0.0862 | ...\n   9. [Doc 1008] ‚ùå FALLO | Score: 0.0857 | ...\n   10. [Doc 270] ‚úÖ ACERTO | Score: 0.0833 | ...\n   RESUMEN: 6/10 relevantes encontrados.\n\n>> MODELO 2: TF-IDF (Vectorial) (Top 10):\n   1. [Doc 500] ‚úÖ ACERTO | Score: 0.4689 | ...\n   2. [Doc 450] ‚ùå FALLO | Score: 0.1880 | ...\n   3. [Doc 87] ‚úÖ ACERTO | Score: 0.1796 | ...\n   4. [Doc 407] ‚úÖ ACERTO | Score: 0.1741 | ...\n   5. [Doc 408] ‚úÖ ACERTO | Score: 0.1681 | ...\n   6. [Doc 268] ‚úÖ ACERTO | Score: 0.1658 | ...\n   7. [Doc 88] ‚úÖ ACERTO | Score: 0.1449 | ...\n   8. [Doc 584] ‚ùå FALLO | Score: 0.1441 | ...\n   9. [Doc 270] ‚úÖ ACERTO | Score: 0.1361 | ...\n   10. [Doc 607] ‚ùå FALLO | Score: 0.1351 | ...\n   RESUMEN: 7/10 relevantes encontrados.\n\n>> MODELO 3: BM25 (Probabil√≠stico) (Top 10):\n   1. [Doc 500] ‚úÖ ACERTO | Score: 31.6903 | ...\n   2. [Doc 268] ‚úÖ ACERTO | Score: 16.6599 | ...\n   3. [Doc 88] ‚úÖ ACERTO | Score: 16.2980 | ...\n   4. [Doc 270] ‚úÖ ACERTO | Score: 16.1909 | ...\n   5. [Doc 87] ‚úÖ ACERTO | Score: 16.1127 | ...\n   6. [Doc 407] ‚úÖ ACERTO | Score: 15.7140 | ...\n   7. [Doc 450] ‚ùå FALLO | Score: 15.7111 | ...\n   8. [Doc 267] ‚úÖ ACERTO | Score: 14.0176 | ...\n   9. [Doc 408] ‚úÖ ACERTO | Score: 13.0451 | ...\n   10. [Doc 396] ‚ùå FALLO | Score: 13.0249 | ...\n   RESUMEN: 8/10 relevantes encontrados.\n\n============================================================\n","output_type":"stream"}],"execution_count":105},{"cell_type":"code","source":"def main():\n    while True:\n        print(\"\\n\" + \"=\"*50)\n        print(\" MOTOR DE B√öSQUEDA CRANFIELD (AERODIN√ÅMICA)\")\n        print(\"=\"*50)\n        print(\"1. Consultar (Jaccard)\")\n        print(\"2. Consultar (TF-IDF)\")\n        print(\"3. Consultar (BM25)\")\n        print(\"4. Evaluar Sistema Completo\")\n        print(\"5. Salir\")\n        \n        opc = input(\"\\nOpci√≥n: \")\n        \n        if opc == '5': \n            print(\"Saliendo...\")\n            break\n        elif opc == '4':\n            evaluar_sistema_completo('Jaccard')\n            evaluar_sistema_completo('TF-IDF')\n            evaluar_sistema_completo('BM25')\n        elif opc in ['1', '2', '3']:\n            consulta = input(\"Consulta: \")\n            print(f\"Buscando: '{consulta}'...\")\n            \n            res = []\n            if opc == '1': res = busqueda_jaccard(consulta, corpus_tokens)\n            elif opc == '2': res = busqueda_tfidf(consulta, matriz_tfidf, vocab, idf_tfidf)\n            elif opc == '3': res = busqueda_bm25(consulta, corpus_tokens, doc_lengths, avgdl, idf_bm25)\n            \n            print(\"\\n--- Resultados ---\")\n            for i, (idx, score) in enumerate(res):\n                doc_id = map_indices_id[idx]\n                prev = documents[doc_id]['W'][:80].replace('\\n', ' ')\n                print(f\"{i+1}. [Doc {doc_id}] (Score {score:.4f}): {prev}...\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T03:54:31.545855Z","iopub.execute_input":"2025-12-10T03:54:31.546124Z","iopub.status.idle":"2025-12-10T04:03:40.545397Z","shell.execute_reply.started":"2025-12-10T03:54:31.546096Z","shell.execute_reply":"2025-12-10T04:03:40.543742Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\n MOTOR DE B√öSQUEDA CRANFIELD (AERODIN√ÅMICA)\n==================================================\n1. Consultar (Jaccard)\n2. Consultar (TF-IDF)\n3. Consultar (BM25)\n4. Evaluar Sistema Completo\n5. Salir\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nOpci√≥n:  4\n"},{"name":"stdout","text":"\n--- Evaluando Modelo: Jaccard ---\nResultados Globales Jaccard:\n-> MAP:          0.1767\n-> Precision@10: 0.2071\n-> Recall@10:    0.2016\n\n--- Evaluando Modelo: TF-IDF ---\nResultados Globales TF-IDF:\n-> MAP:          0.2548\n-> Precision@10: 0.2862\n-> Recall@10:    0.2721\n\n--- Evaluando Modelo: BM25 ---\nResultados Globales BM25:\n-> MAP:          0.2706\n-> Precision@10: 0.2956\n-> Recall@10:    0.2799\n\n==================================================\n MOTOR DE B√öSQUEDA CRANFIELD (AERODIN√ÅMICA)\n==================================================\n1. Consultar (Jaccard)\n2. Consultar (TF-IDF)\n3. Consultar (BM25)\n4. Evaluar Sistema Completo\n5. Salir\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/2774705748.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_47/2774705748.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"5. Salir\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mopc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nOpci√≥n: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'5'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"],"ename":"KeyboardInterrupt","evalue":"Interrupted by user","output_type":"error"}],"execution_count":103}]}